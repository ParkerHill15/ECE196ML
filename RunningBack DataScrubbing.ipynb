{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries for the proper scrubbing of all data\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating \n",
    "data = pd.DataFrame()\n",
    "for i in range(2002,2020):\n",
    "    url_text = requests.get(f'https://www.pro-football-reference.com/years/{i}/opp.htm').text\n",
    "    soup = BeautifulSoup(url_text)\n",
    "    teams = []\n",
    "    iterator = 0\n",
    "    for x in range(0,32):\n",
    "        teams.append(soup.find_all('td')[iterator].text)\n",
    "        iterator += 27\n",
    "    data[f'{i}'] = teams\n",
    "data.to_csv('Defense.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will be a function which will be called which correlates a teams 3 letter acronym to their actual team\n",
    "def findTeam(name,year):\n",
    "    team = ''\n",
    "    if name == 'ARI': team = 'Arizona Cardinals'\n",
    "    elif name == 'ATL': team = 'Atlanta Falcons'\n",
    "    elif name == 'BAL': team = 'Baltimore Ravens'\n",
    "    elif name == 'BUF': team = 'Buffalo Bills'\n",
    "    elif name == 'CAR': team = 'Carolina Panthers'\n",
    "    elif name == 'CHI': team = 'Chicago Bears'\n",
    "    elif name == 'CIN': team = 'Cincinnati Bengals'\n",
    "    elif name == 'CLE': team = 'Cleveland Browns'\n",
    "    elif name == 'DAL': team = 'Dallas Cowboys'\n",
    "    elif name == 'DEN': team = 'Denver Broncos'\n",
    "    elif name == 'DET': team = 'Detroit Lions'\n",
    "    elif name == 'GNB': team = 'Green Bay Packers'\n",
    "    elif name == 'HOU': team = 'Houston Texans'\n",
    "    elif name == 'IND': team = 'Indianapolis Colts'\n",
    "    elif name == 'JAX': team = 'Jacksonville Jaguars'\n",
    "    elif name == 'KAN': team = 'Kansas City Chiefs'\n",
    "    elif name == 'MIA': team = 'Miami Dolphins'\n",
    "    elif name == 'MIN': team = 'Minnesota Vikings'\n",
    "    elif name == 'NWE': team = 'New England Patriots'\n",
    "    elif name == 'NOR': team = 'New Orlean Saints'\n",
    "    elif name == 'NYG': team = 'New York Giants'\n",
    "    elif name == 'NYJ': team = 'New York Jets'\n",
    "    elif name == 'LVR': team = 'Las Vegas Raiders'\n",
    "    elif name == 'PHI': team = 'Philadelphia Eagles'\n",
    "    elif name == 'PIT': team = 'Pittsburgh Steelers'\n",
    "    elif name == 'LAC': team = 'Los Angeles Chargers'\n",
    "    elif name == 'SFO': team = 'San Francisco 49ers'\n",
    "    elif name == 'SEA': team = 'Seattle Seahawks'\n",
    "    elif name == 'LAR': team = 'Los Angeles Rams'\n",
    "    elif name == 'TAM': team = 'Tampa Bay Buccaneers'\n",
    "    elif name == 'TEN': team = 'Tennessee Titans'\n",
    "    elif name == 'WAS': team = 'Washington Football Team'\n",
    "    #Special Boys\n",
    "    elif name == 'SDG': team = 'San Diego Chargers'\n",
    "    elif name == 'STL': team = 'St. Louis Rams'\n",
    "    elif name == 'OAK': team = 'Oakland Raiders'\n",
    "    data = pd.read_csv(r'C:\\Users\\Parker Hill\\Desktop\\ECE 196\\NFL Running Back\\Defense.csv')\n",
    "    frame = pd.DataFrame(data)\n",
    "    for i in range(0,32):\n",
    "        iterativeteam = frame[str(year)][i]\n",
    "        if iterativeteam == team:\n",
    "            rank = i\n",
    "            break\n",
    "    return rank + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year                  Name   URLName\n",
      "0    2002.0        Ricky Williams  WillRi00\n",
      "1    2002.0   LaDainian Tomlinson  TomlLa00\n",
      "2    2002.0          Eddie George  GeorEd00\n",
      "3    2002.0         Travis Henry   HenrTr00\n",
      "4    2002.0      Deuce McAllister  McAlDe00\n",
      "5    2002.0          Corey Dillon  DillCo00\n",
      "6    2002.0         Priest Holmes  HolmPr00\n",
      "7    2002.0           Jamal Lewis  LewiJa00\n",
      "8    2002.0           Tiki Barber  BarbTi00\n",
      "9    2002.0      Shaun Alexander   AlexSh00\n",
      "10   2002.0           Fred Taylor  TaylFr00\n",
      "11   2002.0           Ahman Green  GreeAh00\n",
      "12   2002.0        Edgerrin James  JameEd00\n",
      "13   2002.0        Clinton Portis  PortCl00\n",
      "14   2002.0           Duce Staley  StalDu00\n",
      "15   2002.0        Curtis Martin   MartCu00\n",
      "16   2002.0       Michael Bennett  BennMi00\n",
      "17   2002.0         Emmitt Smith   SmitEm00\n",
      "18   2002.0        Antowain Smith  SmitAn00\n",
      "19   2002.0         William Green  GreeWi00\n",
      "20   2002.0         James Stewart  StewJa00\n",
      "21   2002.0          Warrick Dunn  DunnWa00\n",
      "22   2002.0       Garrison Hearst  HearGa00\n",
      "23   2002.0        Anthony Thomas  ThomAn00\n",
      "24   2002.0        Marshall Faulk  FaulMa00\n",
      "25   2002.0           Lamar Smith  SmitLa00\n",
      "26   2002.0        Stephen Davis   DaviSt00\n",
      "27   2002.0       Michael Pittman  PittMi00\n",
      "28   2002.0        Jonathan Wells  WellJo00\n",
      "29   2002.0          Amos Zereoue  ZereAm00\n",
      "..      ...                   ...       ...\n",
      "546  2019.0            Nick Chubb  ChubNi00\n",
      "547  2019.0  Christian McCaffrey   McCaCh00\n",
      "548  2019.0          Chris Carson  CarsCh00\n",
      "549  2019.0             Joe Mixon  MixoJo00\n",
      "550  2019.0    Leonard Fournette   FourLe00\n",
      "551  2019.0           Dalvin Cook  CookDa00\n",
      "552  2019.0           Marlon Mack  MackMa00\n",
      "553  2019.0           Sony Michel  MichSo00\n",
      "554  2019.0           LeVeon Bell  BellLe00\n",
      "555  2019.0           Carlos Hyde  HydeCa00\n",
      "556  2019.0           Josh Jacobs  JacoJo00\n",
      "557  2019.0      David Montgomery  MontDa00\n",
      "558  2019.0           Aaron Jones  JoneAa00\n",
      "559  2019.0       Phillip Lindsay  LindPh00\n",
      "560  2019.0           Todd Gurley  GurlTo00\n",
      "561  2019.0        Saquon Barkley  BarkSa00\n",
      "562  2019.0       Adrian Peterson  PeteAd00\n",
      "563  2019.0           Mark Ingram  IngrMa00\n",
      "564  2019.0      Devonta Freeman   FreeDe00\n",
      "565  2019.0        Miles Sanders   SandMi00\n",
      "566  2019.0         Lamar Jackson  JackLa00\n",
      "567  2019.0       Ronald Jones II  JoneRo00\n",
      "568  2019.0          Alvin Kamara  KamaAl00\n",
      "569  2019.0          Kenyan Drake  DrakKe00\n",
      "570  2019.0            Frank Gore  GoreFr00\n",
      "571  2019.0         Melvin Gordon  GordMe00\n",
      "572  2019.0         Peyton Barber  BarbPe00\n",
      "573  2019.0      Devin Singletary  SingDe00\n",
      "574  2019.0       Latavius Murray  MurrLa00\n",
      "575  2019.0         Tevin Coleman  ColeTe00\n",
      "\n",
      "[576 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#https://www.pro-football-reference.com/years/2002/rushing.htm\n",
    "#Need to make it so that names and acronyms are saved for in a list so that they can be referenced for urls\n",
    "rb_data = pd.DataFrame()\n",
    "rb_data['Year'] = []\n",
    "rb_data['Name'] = []\n",
    "rb_data['URLName']= []\n",
    "for year in range(2002,2020):\n",
    "    url_text = requests.get(f'https://www.pro-football-reference.com/years/{year}/rushing.htm').text\n",
    "    soup = BeautifulSoup(url_text)\n",
    "    iterator = 0\n",
    "    years = []\n",
    "    name = []\n",
    "    url = []\n",
    "    for x in range(0,32):\n",
    "        newstr = ''\n",
    "        urlname = ''\n",
    "        player = soup.find_all('td')[iterator].text\n",
    "        alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz '\n",
    "        for i in range(0,len(player)):\n",
    "            if alphabet.find(player[i]) != -1:\n",
    "                newstr += player[i]\n",
    "        for i in range(0,len(newstr)):\n",
    "            if newstr[i] == ' ':\n",
    "                urlname = newstr[i+1]+newstr[i+2]+newstr[i+3]+newstr[i+4]\n",
    "                break\n",
    "        urlname = urlname + player[0] + player[1] + '00'\n",
    "        new_row = {'Year':year,'Name':newstr,'URLName':urlname}\n",
    "        rb_data = rb_data.append(new_row,ignore_index = True)\n",
    "        iterator += 14\n",
    "print(rb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_data.to_csv('RunningBacks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
